{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear and Logistic Regression\n",
    "### Simple, yet powerful predictiors\n",
    "\n",
    "\n",
    "\n",
    "## Linear Regression:\n",
    "### Predict continuous values\n",
    "### Intuition\n",
    "- Regression: predicting a continuous variable\n",
    "- Problem statement:\n",
    "    - given pairs of (x, y) points, create a model\n",
    "        - input x, output y: goal: predict y given x\n",
    "                - under the ssumption that y depends linearly on x(and nothing else)\n",
    "- Modelling function:\n",
    "    - $ \\tilde{y} = ax + b $\n",
    "    - many samples: for each sample $ (x_1,, y_1), ... , (x_m, y_m) $\n",
    "        - $ \\tilde{y_i} = ax_i + b, i \\in [1; m] $\n",
    "        - many variables: $ \\tilde{y} = a_1.x_1 + a_2.x_2 + ... + a_n.x_n +   b   \\equiv a^T.X + b $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "- Loss function:\n",
    "    - for each sample i, $ i \\in [1,m] $\n",
    "    - $ d_i = (\\tilde{y_i} - y_i)^2$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Total cost function:\n",
    "    - also called simply \"cost function\"\n",
    "    - $ J = 1/m \\sum\\limits_{i=1}^m (\\tilde{y_i} - y_i)^2 $\n",
    "    - *J* depends on a,b,x,y\n",
    "    \n",
    "- Training process:\n",
    "    - minimize the cost function:\n",
    "        - we're looking for parameters a,b that lead to min J\n",
    "        - written as \"arg min J\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent\n",
    "- Input a,b, output J\n",
    "- Parabloid (3D parabola)\n",
    "    - it has exactly one min value\n",
    "        - and we can see it\n",
    "- Intuition:\n",
    "    - if the plot was a real object (say, a scheet of some sort), we could  slide a ball bearing on it\n",
    "    - after a while, hte ball bearing will settle at the 'bottom' due to gravity\n",
    "    - we can 'simulate' this : **gradient descent**\n",
    "- Reminder: gradient:\n",
    "        - multi 0dimensional derivative:\n",
    "$\\nabla J = \\Bigg\\{ \\frac{\\frac{\\frac{\\partial J}{\\partial a}}{\\frac{\\partial J}{\\partial b}} \\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DEMO\n",
    "### Multiple Linear regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = pd.read_csv(\"data/housing.data\", header=None,sep='\\s+')\n",
    "housing.columns = [\"crime_rate\", \"zoned_land\", \"industry\", \"bounds_river\",\n",
    "\"nox_conc\", \"rooms\", \"age\", \"distance\", \"highways\", \"tax\", \"pt_ratio\",\n",
    "\"b_estimator\", \"pop_status\", \"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crime_rate</th>\n",
       "      <th>zoned_land</th>\n",
       "      <th>industry</th>\n",
       "      <th>bounds_river</th>\n",
       "      <th>nox_conc</th>\n",
       "      <th>rooms</th>\n",
       "      <th>age</th>\n",
       "      <th>distance</th>\n",
       "      <th>highways</th>\n",
       "      <th>tax</th>\n",
       "      <th>pt_ratio</th>\n",
       "      <th>b_estimator</th>\n",
       "      <th>pop_status</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>501</td>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>502</td>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>503</td>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>504</td>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>505</td>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     crime_rate  zoned_land  industry  bounds_river  nox_conc  rooms   age  \\\n",
       "0       0.00632        18.0      2.31             0     0.538  6.575  65.2   \n",
       "1       0.02731         0.0      7.07             0     0.469  6.421  78.9   \n",
       "2       0.02729         0.0      7.07             0     0.469  7.185  61.1   \n",
       "3       0.03237         0.0      2.18             0     0.458  6.998  45.8   \n",
       "4       0.06905         0.0      2.18             0     0.458  7.147  54.2   \n",
       "..          ...         ...       ...           ...       ...    ...   ...   \n",
       "501     0.06263         0.0     11.93             0     0.573  6.593  69.1   \n",
       "502     0.04527         0.0     11.93             0     0.573  6.120  76.7   \n",
       "503     0.06076         0.0     11.93             0     0.573  6.976  91.0   \n",
       "504     0.10959         0.0     11.93             0     0.573  6.794  89.3   \n",
       "505     0.04741         0.0     11.93             0     0.573  6.030  80.8   \n",
       "\n",
       "     distance  highways    tax  pt_ratio  b_estimator  pop_status  price  \n",
       "0      4.0900         1  296.0      15.3       396.90        4.98   24.0  \n",
       "1      4.9671         2  242.0      17.8       396.90        9.14   21.6  \n",
       "2      4.9671         2  242.0      17.8       392.83        4.03   34.7  \n",
       "3      6.0622         3  222.0      18.7       394.63        2.94   33.4  \n",
       "4      6.0622         3  222.0      18.7       396.90        5.33   36.2  \n",
       "..        ...       ...    ...       ...          ...         ...    ...  \n",
       "501    2.4786         1  273.0      21.0       391.99        9.67   22.4  \n",
       "502    2.2875         1  273.0      21.0       396.90        9.08   20.6  \n",
       "503    2.1675         1  273.0      21.0       396.90        5.64   23.9  \n",
       "504    2.3889         1  273.0      21.0       393.45        6.48   22.0  \n",
       "505    2.5050         1  273.0      21.0       396.90        7.88   11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Model\n",
    "- Like in 2D example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.08011358e-01  4.64204584e-02  2.05586264e-02  2.68673382e+00\n",
      " -1.77666112e+01  3.80986521e+00  6.92224640e-04 -1.47556685e+00\n",
      "  3.06049479e-01 -1.23345939e-02 -9.52747232e-01  9.31168327e-03\n",
      " -5.24758378e-01]\n",
      "36.4594883850897\n"
     ]
    }
   ],
   "source": [
    "housing_model = LinearRegression()\n",
    "predictor_attributes = housing.drop(\"price\", axis = 1)\n",
    "housing_model.fit(predictor_attributes, housing.price)\n",
    "print(housing_model.coef_)\n",
    "print(housing_model.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23.37308644 19.29559075 18.52177132  6.4519857  27.41266734 26.12796681\n",
      " 27.2136458  22.14837562 23.98742856 21.28152535]\n",
      "64     33.0\n",
      "396    12.5\n",
      "422    20.8\n",
      "388    10.2\n",
      "91     22.0\n",
      "504    22.0\n",
      "288    22.3\n",
      "349    26.6\n",
      "62     22.2\n",
      "50     19.7\n",
      "Name: price, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "test_houses = housing.sample(10)\n",
    "predicted = housing_model.predict(\n",
    "test_houses.drop(\"price\", axis = 1))\n",
    "print(predicted)\n",
    "print(test_houses.price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression with Outliers:\n",
    "- As we saw, the data has outliers:\n",
    "    - a few points which are far from the others\n",
    "- Our gial is to exlude outliers:\n",
    "    - there are several methods:\n",
    "        - one very common - RANSAC (RANdom SAmple Consensus)\n",
    "- ALgorithm:\n",
    "    1. Fit a model to a random subsample('inliers')\n",
    "    2. Test all data points and include those which are 'near' the model:\n",
    "        - small enough error, tolerance provided by developer\n",
    "    3. Fit the model again\n",
    "    4. Estimate the error of the model (difference between first and second)\n",
    "    5. Iterate steps 1-4 until performance reaches a threshold or number of iterations\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.07899484e-01  6.28661556e-02 -1.15380345e-01  3.66246719e-01\n",
      " -6.96164418e+00  8.34530244e+00 -8.51878916e-02 -1.13187113e+00\n",
      "  1.13685351e-01  1.28236622e-03 -7.13848885e-01  2.83922510e-02\n",
      "  1.12029668e-01] -14.952407698402258\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RANSACRegressor\n",
    "ransac = RANSACRegressor()\n",
    "ransac.fit(housing.drop(\"price\", axis = 1), housing.price)\n",
    "print(ransac.estimator_.coef_, ransac.estimator_.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can also privide parameters, e.g. min number of random samples, max iterations, threshold (to include data points)\n",
    "- We can also provide the type of model we want to perform RANSAC on\n",
    "    - Linear regression by default but we may use other refression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "ransac = RANSACRegressor(LinearRegression(), min_samples = 50,\n",
    "max_trials = 100, residual_threshold = 5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RANSACRegressor' object has no attribute 'inlier_mask_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-c15c0f218c70>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# view inliers and outliers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0minliers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhousing\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mransac\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minlier_mask_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0moutliers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhousing\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mransac\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minlier_mask_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minliers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrooms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minliers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutliers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrooms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutliers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'RANSACRegressor' object has no attribute 'inlier_mask_'"
     ]
    }
   ],
   "source": [
    "# view inliers and outliers\n",
    "inliers = housing[ransac.inlier_mask_]\n",
    "outliers = housing[~ransac.inlier_mask_]\n",
    "plt.scatter(inliers.rooms, inliers.price)\n",
    "plt.scatter(outliers.rooms, outliers.price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Regression\n",
    "- Extension of the linear regression algorithm\n",
    "    - we can use the linear regression algorithm to perform polynomial regression(e.g. fitting a quadratic curve)\n",
    "    - Just precompute the columns:\n",
    "        - example 1:\n",
    "        - example 2: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', 'x0', 'x1', 'x0^2', 'x0 x1', 'x1^2']\n",
      "2\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "x = np.arange(6).reshape(3, 2)\n",
    "poly = PolynomialFeatures(2)\n",
    "x_transformed = poly.fit_transform(x)\n",
    "print(poly.get_feature_names())\n",
    "print(poly.n_input_features_)\n",
    "print(poly.n_output_features_)\n",
    "# Now we can perform linear regression with x_transformed as the input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Mistakes:\n",
    "- There are two main types of errors we can make while trying regression models\n",
    "    - Use a **wrong model** : anscombe's quartet\n",
    "    - **Extrapolate** without knowing (expecially if we have interacting features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "### Use a regression model to classify\n",
    "\n",
    "### Classification\n",
    "- Predict **one of several known classes**\n",
    "    - based on the imput parameters\n",
    "    - ex: classify whether a picture is of a cat or a dog\n",
    "- Regression and classification make up most of the machine learning problems\n",
    "- Choosing an algorithm:\n",
    "    - 'No free lunc': no single algorithm works best\n",
    "    - It's best to compare some algorithms to select best for a particular model\n",
    "        - also, we might want to tune them first\n",
    "    - Reminder: ML process\n",
    "        - select features, choose a performance metric (cost function), choose a classifier, evaluate and fine-tune the performance\n",
    "- Classification algorithm (despite its name)\n",
    "- Two classes: negative-(0) and positive (1)\n",
    "        - can be extended to more classes\n",
    "- How does it work?\n",
    "    - linear refression can give us all kinds of values\n",
    "    - we want to constrain them between 0 and 1\n",
    "    - approach:\n",
    "         - perform linear regression: $ \\widetilde{y} = \\beta x $\n",
    "    - use the sigmoid function to constrain the output:\n",
    "$$ \\sigma (\\widetilde{y}) = \\frac{1}{ 1 + e^{\\tilde{-y}} = \\frac{1}{ 1 + e^{- \\beta^T . x}}   } $$\n",
    "\n",
    "\n",
    "- Quantization: if $ \\sigma > 0.5 $ return 1, and 0 otherwise\n",
    "    - remember that we only need to return 0 or 1\n",
    "    - we can also use the raw values as probability measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'iris_train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-bc9b989e692d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1e6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miris_train_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miris_train_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'iris_train_data' is not defined"
     ]
    }
   ],
   "source": [
    "# perform logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(C = 1e6)\n",
    "model.fit(iris_train_data, iris_train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test output classes or probabilities\n",
    "print(model.predict(iris_test))\n",
    "print(model.predict_proba(iris_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the model, there's a 'mysterious' parameter C\n",
    "    - regularization: how powerful the data is (more-next time)\n",
    "    - a large number means no regularization\n",
    "        - we just take the data 'as-is' , with no other constraints\n",
    "### Many Classes\n",
    "- Two main approaches\n",
    "    - One-vs-all: several predictors\n",
    "        - one predictor for each class vs.the others\n",
    "    - Overall: calculate probabilities of each class\n",
    "- scikit-learn takes care of multiple classes - multinomial logistic regression by default\n",
    "    - we don't even need to transform the labels\n",
    "    - this applies to all algorithms in the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
